#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ë‰´ìŠ¤ í•¸ë“¤ëŸ¬ ëª¨ë“ˆ
ë‰´ìŠ¤ ê´€ë ¨ ëª…ë ¹ì–´ ì²˜ë¦¬
"""

import urllib.parse
from datetime import datetime, timezone, timedelta
from utils.debug_logger import debug_logger

# í•œêµ­ ì‹œê°„ëŒ€ (KST = UTC+9)
KST = timezone(timedelta(hours=9))

def get_kst_time():
    """í•œêµ­ ì‹œê°„ ë°˜í™˜"""
    return datetime.now(KST).strftime("%Y-%m-%d %H:%M")

# request í•¨ìˆ˜ë¥¼ fn.pyì—ì„œ ê°€ì ¸ì˜¤ê¸°
try:
    from fn import request
except ImportError:
    # í´ë°±: ì§ì ‘ êµ¬í˜„
    import requests
    from bs4 import BeautifulSoup
    
    def request(url, method="get", result="text", params=None, headers=None):
        """HTTP ìš”ì²­ í—¬í¼ í•¨ìˆ˜"""
        try:
            if method.lower() == "get":
                response = requests.get(url, params=params, headers=headers, timeout=10)
            else:
                response = requests.post(url, params=params, headers=headers, timeout=10)
            
            if result == "json":
                return response.json()
            elif result == "bs":
                return BeautifulSoup(response.text, 'html.parser')
            else:
                return response.text
        except Exception as e:
            print(f"Request error: {e}")
            return None


def economy_news(room: str, sender: str, msg: str):
    """ê²½ì œ ë‰´ìŠ¤ - ë„¤ì´ë²„ Open API ì‚¬ìš©"""
    return _category_news("ê²½ì œ", "ê²½ì œ", "ë¶€ë™ì‚° ì£¼ì‹ ê²½ì œ")


def it_news(room: str, sender: str, msg: str):
    """IT ë‰´ìŠ¤ - ë„¤ì´ë²„ Open API ì‚¬ìš©"""
    return _category_news("IT", "ITê³¼í•™", "í…Œí¬ ê¸°ìˆ ")


def realestate_news(room: str, sender: str, msg: str):
    """ë¶€ë™ì‚° ë‰´ìŠ¤ - ë„¤ì´ë²„ Open API ì‚¬ìš©"""
    return _category_news("ë¶€ë™ì‚°", "ë¶€ë™ì‚°", "ì•„íŒŒíŠ¸ ì£¼íƒ ì§‘ê°’")


def _category_news(category_name: str, display_name: str, search_keywords: str):
    """
    ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° - ë„¤ì´ë²„ Open API ì‚¬ìš©

    Args:
        category_name: ì¹´í…Œê³ ë¦¬ ì´ë¦„ (emojiìš©)
        display_name: í‘œì‹œ ì´ë¦„
        search_keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ (ê³µë°± êµ¬ë¶„)
    """
    # ë„¤ì´ë²„ Open API í‚¤ ê°€ì ¸ì˜¤ê¸°
    try:
        import os
        client_id = os.getenv("NAVER_CLIENT_ID", "")
        client_secret = os.getenv("NAVER_CLIENT_SECRET", "")

        if not client_id or not client_secret:
            debug_logger.error("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return _fallback_category_news(category_name, display_name)
    except ImportError:
        return _fallback_category_news(category_name, display_name)

    try:
        # ë„¤ì´ë²„ Open API - ë‰´ìŠ¤ ê²€ìƒ‰
        encode_keyword = urllib.parse.quote(search_keywords.split()[0])
        url = f"https://openapi.naver.com/v1/search/news.json?query={encode_keyword}&display=5&sort=date"

        headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret,
        }

        response = request(url, method="get", result="text", headers=headers)

        if not response:
            return _fallback_category_news(category_name, display_name)

        import json
        import re
        data = json.loads(response)

        if data.get('errorCode'):
            debug_logger.error(f"ë„¤ì´ë²„ API ì˜¤ë¥˜: {data.get('errorMessage')}")
            return _fallback_category_news(category_name, display_name)

        items = data.get('items', [])

        if not items:
            return _fallback_category_news(category_name, display_name)

        # ì´ëª¨ì§€ ë§¤í•‘
        emoji_map = {"ê²½ì œ": "ğŸ’°", "IT": "ğŸ’»", "ë¶€ë™ì‚°": "ğŸ "}
        emoji = emoji_map.get(category_name, "ğŸ“°")

        send_msg = f"{emoji} {display_name} ë‰´ìŠ¤ ğŸ“º\nğŸ“… {get_kst_time()} ê¸°ì¤€"

        for idx, item in enumerate(items[:5], 1):
            title = item.get('title', '')
            description = item.get('description', '')
            link = item.get('originallink') or item.get('link', '')
            source = item.get('source', '')

            # HTML íƒœê·¸ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°
            title = re.sub(r'<[^>]+>', '', title)
            title = title.replace('&quot;', '"').replace('&apos;', "'")
            title = title.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
            description = re.sub(r'<[^>]+>', '', description)
            description = description.replace('&quot;', '"').replace('&apos;', "'")
            description = description.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')

            # ì„¤ëª…ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
            if len(description) > 100:
                description = description[:97] + "..."

            # í•´ì‹œíƒœê·¸ ìƒì„± (ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ)
            tags = []

            # ì¶œì²˜ ì¶”ê°€
            if source:
                tags.append(f"(ì¶œì²˜:{source})")

            # ì„¤ëª…ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ í•œê¸€)
            words = re.findall(r'[ê°€-í£]{2,}', description)
            unique_words = list(dict.fromkeys(words))[:3]  # ì¤‘ë³µ ì œê±°, ìµœëŒ€ 3ê°œ
            for word in unique_words:
                tags.append(f"#{word}")

            tag_str = ' '.join(tags) if tags else ""

            # ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ ë³€í™˜
            if link and 'news.naver.com' in link:
                match = re.search(r'/article/(\d+)/(\d+)', link)
                if match:
                    office_id, article_id = match.groups()
                    link = f"https://n.news.naver.com/mnews/article/{office_id}/{article_id}"

            # ë©”ì‹œì§€ êµ¬ì„±
            news_item = f"\n\n{idx}. {title}"
            if description:
                news_item += f"\n{description}"
            if tag_str:
                news_item += f"\n{tag_str}"
            news_item += f"\n{link}"

            send_msg += news_item

        return send_msg

    except Exception as e:
        debug_logger.error(f"{display_name} ë‰´ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        return _fallback_category_news(category_name, display_name)


def _fallback_category_news(category_name: str, display_name: str):
    """API ì‹¤íŒ¨ì‹œ í´ë°± - ìŠ¤í¬ë˜í•‘ ë°©ì‹"""
    emoji_map = {"ê²½ì œ": "ğŸ’°", "IT": "ğŸ’»", "ë¶€ë™ì‚°": "ğŸ "}
    emoji = emoji_map.get(category_name, "ğŸ“°")

    # ì¹´í…Œê³ ë¦¬ë³„ URL ë§¤í•‘
    area_map = {"ê²½ì œ": 101, "IT": 105, "ë¶€ë™ì‚°": 260}
    area = area_map.get(category_name, 101)

    try:
        if category_name == "ë¶€ë™ì‚°":
            url = f'https://m.news.naver.com/rankingList?sid1=101&sid2={area}'
        else:
            url = f'https://m.news.naver.com/main?mode=LSD&sid1={area}'

        result = request(url, method="get", result="bs")
        send_msg = f"{emoji} {display_name} ë‰´ìŠ¤ ğŸ“º\nğŸ“… {get_kst_time()} ê¸°ì¤€"

        news_items = result.select('li.sa_item')
        if not news_items:
            return f"{emoji} {display_name} ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        for idx, item in enumerate(news_items[:5], 1):
            title_elem = item.select_one('.sa_text_strong')
            link_elem = item.select_one('.sa_text_title')

            if title_elem and link_elem:
                title = title_elem.text.strip()
                link = link_elem.get('href', '')
                send_msg += f'\n\n{idx}. {title}\n{link}'

        return send_msg

    except Exception as e:
        debug_logger.error(f"{display_name} ë‰´ìŠ¤ í´ë°± ì˜¤ë¥˜: {str(e)}")
        return f"{emoji} {display_name} ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


def search_news(room: str, sender: str, msg: str):
    """ë‰´ìŠ¤ ê²€ìƒ‰ - ë„¤ì´ë²„ Open API ì‚¬ìš©"""
    keyword = msg.replace("/ë‰´ìŠ¤", "").strip()
    if not keyword:
        return "ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì‚¬ìš©ë²•: /ë‰´ìŠ¤ í‚¤ì›Œë“œ)"

    # ë„¤ì´ë²„ Open API í‚¤ ê°€ì ¸ì˜¤ê¸°
    try:
        import os
        client_id = os.getenv("NAVER_CLIENT_ID", "")
        client_secret = os.getenv("NAVER_CLIENT_SECRET", "")

        if not client_id or not client_secret:
            debug_logger.error("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return _search_news_google_fallback(keyword, request)
    except ImportError:
        return _search_news_google_fallback(keyword, request)

    try:
        # ë„¤ì´ë²„ Open API - ë‰´ìŠ¤ ê²€ìƒ‰
        encode_keyword = urllib.parse.quote(keyword)
        url = f"https://openapi.naver.com/v1/search/news.json?query={encode_keyword}&display=5&sort=date"

        headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret,
        }

        response = request(url, method="get", result="text", headers=headers)

        if not response:
            return _search_news_google_fallback(keyword, request)

        import json
        data = json.loads(response)

        if data.get('errorCode'):
            debug_logger.error(f"ë„¤ì´ë²„ API ì˜¤ë¥˜: {data.get('errorMessage')}")
            return _search_news_google_fallback(keyword, request)

        items = data.get('items', [])

        if not items:
            return _search_news_google_fallback(keyword, request)

        send_msg = f"ğŸ“° {keyword} ë‰´ìŠ¤ ğŸ“º\nğŸ“… {get_kst_time()} ê¸°ì¤€"

        import re
        for item in items[:5]:
            title = item.get('title', '')
            link = item.get('originallink') or item.get('link', '')

            # ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ ë³€í™˜
            if link and 'news.naver.com' in link:
                match = re.search(r'/article/(\d+)/(\d+)', link)
                if match:
                    office_id, article_id = match.groups()
                    link = f"https://n.news.naver.com/mnews/article/{office_id}/{article_id}"

            # HTML íƒœê·¸ ë° íŠ¹ìˆ˜ ë¬¸ì ì œê±°
            title = re.sub(r'<[^>]+>', '', title)
            title = title.replace('&quot;', '"').replace('&apos;', "'")
            title = title.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')

            # ì¶œì²˜ ì¶”ì¶œ
            source_elem = item.get('description', '')
            source_match = re.search(r'([ê°€-í£A-Za-z]+)\s*\(', source_elem)
            source = source_match.group(1) if source_match else ''
            if not source:
                source = item.get('source', '')

            if title:
                # í•´ì‹œíƒœê·¸ ìƒì„±
                tags = []
                keyword_parts = [w.strip() for w in keyword.split() if w.strip() and len(w) > 1]
                for part in keyword_parts[:3]:
                    tags.append(f"#{part}")

                if source:
                    tags.append(f"(ì¶œì²˜:{source})")

                tag_str = ' '.join(tags) if tags else ""

                send_msg += f"\n\n{title}"
                if tag_str:
                    send_msg += f" {tag_str}"
                send_msg += f"\n{link}"

        return send_msg

    except Exception as e:
        debug_logger.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜ ({keyword}): {str(e)}")
        return _search_news_google_fallback(keyword, request)


def _search_news_google_fallback(keyword: str, request_func) -> str:
    """Google News RSS í´ë°±"""
    try:
        encode_keyword = urllib.parse.quote(keyword)
        url = f'https://news.google.com/rss/search?q={encode_keyword}&hl=ko&gl=KR&ceid=KR:ko'

        result = request_func(url, method="get", result="text")
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(result, 'xml')
        items = soup.find_all('item')[:5]

        if not items:
            return f"'{keyword}'ì— ëŒ€í•œ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        send_msg = f"ğŸ“° {keyword} ë‰´ìŠ¤ ğŸ“º\nğŸ“… {get_kst_time()} ê¸°ì¤€"

        for item in items:
            title = item.find('title')
            link = item.find('link')
            source = item.find('source')

            title_text = title.text if title else ''
            link_text = link.text if link else ''
            source_text = source.text if source else ''

            if title_text:
                tags = []
                keyword_words = [w.strip() for w in keyword.split() if w.strip() and len(w) > 1]
                for word in keyword_words[:3]:
                    tags.append(f"#{word}")

                if source_text:
                    tags.append(f"(ì¶œì²˜:{source_text})")

                tag_str = ' '.join(tags) if tags else ""

                send_msg += f"\n\n{title_text}"
                if tag_str:
                    send_msg += f" {tag_str}"
                send_msg += f"\n{link_text}"

        return send_msg

    except Exception as e:
        debug_logger.error(f"Google News í´ë°± ì˜¤ë¥˜: {str(e)}")
        return f"'{keyword}' ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


def real_news(room: str, sender: str, msg: str):
    """ì‹¤ì‹œê°„ ë‰´ìŠ¤"""
    url = 'https://news.naver.com/section/template/MOBILE_RANKING_ARTICLE'
    
    try:
        result = request(url, method="get", result="json")
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        # ë‰´ìŠ¤ ë°ì´í„° ì¶”ì¶œ
        news_list = result.get('renderedComponent', {}).get('props', {}).get('rankingArticleList', [])
        
        if not news_list:
            return "ì‹¤ì‹œê°„ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        send_msg = f"ğŸ“° ì‹¤ì‹œê°„ ì¸ê¸° ë‰´ìŠ¤\nğŸ“… {current_time} ê¸°ì¤€\n"
        
        for idx, article in enumerate(news_list[:10], 1):
            title = article.get('title', '').strip()
            article_id = article.get('articleId', '')
            
            if title and article_id:
                # ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ í˜•ì‹
                link = f"https://n.news.naver.com/article/{article_id}"
                send_msg += f"\n{idx}. {title}\n{link}\n"
        
        return send_msg.strip()
        
    except Exception as e:
        debug_logger.error(f"ì‹¤ì‹œê°„ ë‰´ìŠ¤ ì˜¤ë¥˜: {str(e)}")
        return "ì‹¤ì‹œê°„ ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."